<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.7.2">Jekyll</generator><link href="http://rust.love/feed.xml" rel="self" type="application/atom+xml" /><link href="http://rust.love/" rel="alternate" type="text/html" /><updated>2018-04-28T12:28:58+08:00</updated><id>http://rust.love/</id><title type="html">Rust.Love</title><subtitle>Freedom &amp; Responsibility.</subtitle><entry><title type="html">gPRC 实践应用（1）（一周学习报-第7期）</title><link href="http://rust.love/grpc/grpc-go/go/linkerd/consul/2018/04/27/grpc-go.html" rel="alternate" type="text/html" title="gPRC 实践应用（1）（一周学习报-第7期）" /><published>2018-04-27T00:00:00+08:00</published><updated>2018-04-27T00:00:00+08:00</updated><id>http://rust.love/grpc/grpc-go/go/linkerd/consul/2018/04/27/grpc-go</id><content type="html" xml:base="http://rust.love/grpc/grpc-go/go/linkerd/consul/2018/04/27/grpc-go.html">&gt; 为什么是实践应用（1）？因为每一个软件都有很多事儿，稍后我们会拆分章节分到每一期去整理和讲解。


目前我们有一部分内部服务是通过 gRPC 构建的，这里主要讲下 gRPC 在我们这的一点实践，主要分下面几个主题，帮助大家了解我们的是如何在使用和部署 gRPC 服务的，帮助大家理一下思路。下面这个图，是当前我们 gRPC 服务相关的架构图，之后会针对每一块给大家做个介绍。本期意在讲述我们的架构部署和对应的服务有哪些服务构建，具体细节分期以后再讲。

![gRPC 服务架构图](/assets/images/grpc.jpeg)

### gRPC

RPC（Remote Procedure Call）一种远程调用协议，本身是一种语言无关的协议，简单说就是本地调用远程方法，而这种调用非常简单，对于本地试用者就像调用本地方法一样。关于 RPC 的服务框架有很多，这些框架使得使用 RPC 服务的人，更加专注业务，而不用更多的去关注通信、协议等实现，例如你调用了一个远程方法获取用户信息，在框架范围内只需要在本地执行 **this-&gt;callRemoteUserInfoByUserId(123456)** 就完成了用户信息的获取。 gRPC 也是一种 RPC 服务框架，类似的还有 Facebook 的 thrift，我们的服务扣费等功能，就是 thrift 实现的，还有频次控制服务也是 thrift 的。关于 gRPC 的文档说明和定义，都有了[中文翻译版本](https://skyao.io/learning-grpc/grpc/motivation.html)这里不在复述。

### protobuf

因为 RPC 服务是语言无关的，所以在不同语言上，就需要一个介质进行不同语言之间的数据转换，一般可以理解为不同语言间的序列化和反序列化，现在最常用的可能是 json 格式，例如 php 服务端接口生成的 json 为客户端 android 或者 iOS 提供服务。又如 RPC 服务 java 做服务端，php 做客户端，那么 php 和 java 之间就需要进行数据格式转换，Protocol Buffers 就是 Google 开源的一套数据转换格式（或者称之为协议），而且 Google 也提供了全套的工具，可以根据 protocol buffers 的数据 **.proto** 文件，生成对应的客户端和服务端代码，让不同编程语言之间通过该格式进行数据转换，而这种转换完全又工具生成，我们只关注服务及方法调用和自己的业务，让开发人员从代码、网络交互等工作中解脱出来。

既然是一种协议或者是数据结构，那就又定义这种结构的语法，这里有一个关于 **.proto**  语法的翻译的[中文文档](http://colobu.com/2015/01/07/Protobuf-language-guide/)，（顺便说下这个博客的作者是位技术大牛，上面有很多非常不错的技术文章。），稍后的例子中，我们也会提供一个 **.proto** 的文件。

### Linkerd

Linkerd 是一款开源网络代理，旨在作为服务网格进行部署，用于在应用程序内管理、控制和监视服务到服务通信的专用层，也是一套服务治理框架，他提供了性能看板等服务，通过性能看板我们可以直观的看到当前服务的状态。还有很多更强大的功能，包括负载均衡、服务发现等，也提供了多种部署方式，（之前技术部的微服务分享中有讲过，这里不在复述）。和其类似比较火的还有[Istio](https://istio.io/)

### Consul

Consul 主要是提供服务发现、健康检查等服务的服务，何其相似的软件又大名鼎鼎的 [zookeeper](https://zookeeper.apache.org/)、 [etcd](https://github.com/coreos/etcd) 等。关于服务发现等软件解决的问题不用说太多，大家也都应该了解了。

### 示例

目前我们已经在使用一些 RPC 服务了，就像前面说的线上已经部署了一些 thrift 的服务，还有之前我们推荐服务的也是 gRPC 服务，之前我们一直是作为客户端使用 gRPC 服务，这次的例子主要是客户端和服务端都涉及。当前线上的服务可以通过 host:9990 来查看 dashboard。

下面我们围绕一个 ApplyService 服务来讲解，看看完成一个服务需要我们做哪些事情。

![完成一个服务需要我们做哪些事情？](/assets/images/service_flow.jpeg)

#### 基础环境安装

客户端
- php 的 grpc 扩展
- php 的 composer 扩展包 grpc/grpc google/protobuf

服务端
- go
- grpc-go

proto 工具
- protoc 代码生成工具和对应的语言插件 grpc_php_plugin protoc-gen-go 等

#### 定义 proto 文件

$ cat services/apply/apply.proto
```proto
syntax = &quot;proto3&quot;;

// package 名称，因为不同的语言在 package 管理上方式不同，
// 所以 proto 提供了 option 关键字，来帮助不同语言之间让 package 更加友好
// 因为我们是把这部分服务单独放在项目里的，通过客户端通过 composer 统一管理，
// 所以用了单独的目录和独立的名称空间 pluto，php 生成的代码名称空间就是
// namespace Pluto\Services\Apply;
// 在 composer.json 内加入 autoload 模块
// &quot;autoload&quot; : {
//    &quot;psr-4&quot;: {
//        &quot;Pluto\\&quot;: &quot;grpc/Pluto/&quot;,
//    }
// }
package pluto.services.apply;

// 为了上面所说的生成 golang 友好的 package 而设定的
option go_package = &quot;apply&quot;;

service ApplyService {

    // 一个 rpc 调用
    rpc FetchApplyByUid(ApplyRequest) returns (ApplyResponse) {};
}

// 请求
message ApplyRequest {
    string uid = 1;
}

// 响应
message ApplyResponse {
   string result = 1;
}
```

&gt; 除了正常的业务定义以外，我们跟多方合作时，为了语言上的友好，尽量通过 option 关键字，来定义语言友好的包名，让代码组织起来不混乱。

#### 客户端代码生成

```
protoc --php_out=grpc/ --grpc_out=grpc/ --plugin=protoc-gen-grpc=/usr/local/bin/grpc_php_plugin resource/apply.proto
```

protoc-gen-grpc 这个插件完成了 Client 类的生成，如果不安装该插件也可以生成代码，但是 Client 里面的逻辑要自己去加入。除了生成的基础类以外，我们看下 Client 这个文件
```php
&lt;?php
// GENERATED CODE -- DO NOT EDIT!

namespace Pluto\Services\Apply;

/**
 */
class ApplyServiceClient extends \Grpc\BaseStub {

    /**
     * @param string $hostname hostname
     * @param array $opts channel options
     * @param \Grpc\Channel $channel (optional) re-use channel object
     */
    public function __construct($hostname, $opts, $channel = null) {
        parent::__construct($hostname, $opts, $channel);
    }

    /**
     * @param \Pluto\Services\Apply\ApplyRequest $argument input argument
     * @param array $metadata metadata
     * @param array $options call options
     */
    public function FetchApplyByUid(\Pluto\Services\Apply\ApplyRequest $argument,
      $metadata = [], $options = []) {

        // 注意这一段代码
        // pluto.services.apply.ApplyService 这个就是服务名称，
        // 我们后续会使用到这个名字
        return $this-&gt;_simpleRequest('/pluto.services.apply.ApplyService/FetchApplyByUid',
        $argument,
        ['\Pluto\Services\Apply\ApplyResponse', 'decode'],
        $metadata, $options);
    }

}
```

PHP 客户端调用代码
```php
// 这里需要注意 php 的 grpc 扩展的版本，及时升级最新版，
// 笔者开始时测试 10w 次请求发现客户端内存飙升，查了 github issue 发现是因为有内存泄漏
// 官方在新版本修复了
private function callGrpc($id, $output)
{
    // 请求对象初始化
    $request = new ApplyRequest();
    $request-&gt;setUid($id);

    // 初始化 Client
    // 此处配置的是 linkerd 的 4141 代理端口，我们服务用的是 9527 端口
    // 稍后会说明
    $client = new ApplyServiceClient(&quot;127.0.0.1:4141&quot;, [
        'credentials' =&gt;ChannelCredentials::createInsecure(),
        'timeout' =&gt; 1000000,
    ]);

    // 调用服务
    list($reply, $status) = $client-&gt;FetchApplyByUid($request)-&gt;wait();
    var_dump($reply-&gt;getResult());
    $output-&gt;writeln($reply-&gt;getResult());
}
```
#### 服务单 golang 代码生成

根据自己组织的目录进行代码生成，根据我们的定义，会生成一个 apply.pb.go 文件
```
protoc --go_out=plugins=grpc:. *.proto
```

先整体看下我们 golang 服务端的代码结构
```go
.
├── Makefile
├── README.md
├── bin // 编译后的二进制文件目录
│   └── pluto
├── config // 配置文件
│   └── config.yaml
├── glide.lock
├── glide.yaml
├── logs
├── main.go // 主程序
├── services
│   ├── apply
│   └── apply.go // ApplyService 的业务代码
├── util // 工具等目录
│   ├── init.go
│   └── storage.go
└── vendor // 依赖
    ├── github.com
    ├── golang.org
    ├── google.golang.org
    └── gopkg.in
```

$ cat services/apply/apply.pb.go 注意这部分代码 ServiceName 的注释部分
```go
// Code generated by protoc-gen-go. DO NOT EDIT.
// source: apply.proto

/*
Package apply is a generated protocol buffer package.

It is generated from these files:
    apply.proto

It has these top-level messages:
    ApplyRequest
    ApplyResponse
*/
package apply

import proto &quot;github.com/golang/protobuf/proto&quot;
import fmt &quot;fmt&quot;
import math &quot;math&quot;

import (
    context &quot;golang.org/x/net/context&quot;
    grpc &quot;google.golang.org/grpc&quot;
)

// Reference imports to suppress errors if they are not otherwise used.
var _ = proto.Marshal
var _ = fmt.Errorf
var _ = math.Inf

// This is a compile-time assertion to ensure that this generated file
// is compatible with the proto package it is being compiled against.
// A compilation error at this line likely means your copy of the
// proto package needs to be updated.
const _ = proto.ProtoPackageIsVersion2 // please upgrade the proto package

type ApplyRequest struct {
    Uid string `protobuf:&quot;bytes,1,opt,name=uid&quot; json:&quot;uid,omitempty&quot;`
}

func (m *ApplyRequest) Reset()                    { *m = ApplyRequest{} }
func (m *ApplyRequest) String() string            { return proto.CompactTextString(m) }
func (*ApplyRequest) ProtoMessage()               {}
func (*ApplyRequest) Descriptor() ([]byte, []int) { return fileDescriptor0, []int{0} }

func (m *ApplyRequest) GetUid() string {
    if m != nil {
        return m.Uid
    }
    return &quot;&quot;
}

type ApplyResponse struct {
    Result string `protobuf:&quot;bytes,1,opt,name=result&quot; json:&quot;result,omitempty&quot;`
}

func (m *ApplyResponse) Reset()                    { *m = ApplyResponse{} }
func (m *ApplyResponse) String() string            { return proto.CompactTextString(m) }
func (*ApplyResponse) ProtoMessage()               {}
func (*ApplyResponse) Descriptor() ([]byte, []int) { return fileDescriptor0, []int{1} }

func (m *ApplyResponse) GetResult() string {
    if m != nil {
        return m.Result
    }
    return &quot;&quot;
}

func init() {
    proto.RegisterType((*ApplyRequest)(nil), &quot;pluto.services.apply.ApplyRequest&quot;)
    proto.RegisterType((*ApplyResponse)(nil), &quot;pluto.services.apply.ApplyResponse&quot;)
}

// Reference imports to suppress errors if they are not otherwise used.
var _ context.Context
var _ grpc.ClientConn

// This is a compile-time assertion to ensure that this generated file
// is compatible with the grpc package it is being compiled against.
const _ = grpc.SupportPackageIsVersion4

// Client API for ApplyService service

type ApplyServiceClient interface {
    FetchApplyByUid(ctx context.Context, in *ApplyRequest, opts ...grpc.CallOption) (*ApplyResponse, error)
}

type applyServiceClient struct {
    cc *grpc.ClientConn
}

func NewApplyServiceClient(cc *grpc.ClientConn) ApplyServiceClient {
    return &amp;applyServiceClient{cc}
}

func (c *applyServiceClient) FetchApplyByUid(ctx context.Context, in *ApplyRequest, opts ...grpc.CallOption) (*ApplyResponse, error) {
    out := new(ApplyResponse)
    err := grpc.Invoke(ctx, &quot;/pluto.services.apply.ApplyService/FetchApplyByUid&quot;, in, out, c.cc, opts...)
    if err != nil {
        return nil, err
    }
    return out, nil
}

// Server API for ApplyService service

type ApplyServiceServer interface {
    FetchApplyByUid(context.Context, *ApplyRequest) (*ApplyResponse, error)
}

func RegisterApplyServiceServer(s *grpc.Server, srv ApplyServiceServer) {
    s.RegisterService(&amp;_ApplyService_serviceDesc, srv)
}

func _ApplyService_FetchApplyByUid_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
    in := new(ApplyRequest)
    if err := dec(in); err != nil {
        return nil, err
    }
    if interceptor == nil {
        return srv.(ApplyServiceServer).FetchApplyByUid(ctx, in)
    }
    info := &amp;grpc.UnaryServerInfo{
        Server:     srv,
        FullMethod: &quot;/pluto.services.apply.ApplyService/FetchApplyByUid&quot;,
    }
    handler := func(ctx context.Context, req interface{}) (interface{}, error) {
        return srv.(ApplyServiceServer).FetchApplyByUid(ctx, req.(*ApplyRequest))
    }
    return interceptor(ctx, in, info, handler)
}

var _ApplyService_serviceDesc = grpc.ServiceDesc{
    // 注意这部分代，ServiceName
    // 与之前 PHP 客户端里的生成代码部分 pluto.services.apply.ApplyService
    // 代表了服务的名称，这个名字稍后会用于服务发现服务的注册
    ServiceName: &quot;pluto.services.apply.ApplyService&quot;,
    HandlerType: (*ApplyServiceServer)(nil),
    Methods: []grpc.MethodDesc{
        {
            MethodName: &quot;FetchApplyByUid&quot;,
            Handler:    _ApplyService_FetchApplyByUid_Handler,
        },
    },
    Streams:  []grpc.StreamDesc{},
    Metadata: &quot;apply.proto&quot;,
}

func init() { proto.RegisterFile(&quot;apply.proto&quot;, fileDescriptor0) }

var fileDescriptor0 = []byte{
    // 163 bytes of a gzipped FileDescriptorProto
    0x1f, 0x8b, 0x08, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02, 0xff, 0xe2, 0xe2, 0x4e, 0x2c, 0x28, 0xc8,
    0xa9, 0xd4, 0x2b, 0x28, 0xca, 0x2f, 0xc9, 0x17, 0x12, 0x29, 0xc8, 0x29, 0x2d, 0xc9, 0xd7, 0x2b,
    0x4e, 0x2d, 0x2a, 0xcb, 0x4c, 0x4e, 0x2d, 0xd6, 0x03, 0xcb, 0x29, 0x29, 0x70, 0xf1, 0x38, 0x82,
    0x18, 0x41, 0xa9, 0x85, 0xa5, 0xa9, 0xc5, 0x25, 0x42, 0x02, 0x5c, 0xcc, 0xa5, 0x99, 0x29, 0x12,
    0x8c, 0x0a, 0x8c, 0x1a, 0x9c, 0x41, 0x20, 0xa6, 0x92, 0x3a, 0x17, 0x2f, 0x54, 0x45, 0x71, 0x41,
    0x7e, 0x5e, 0x71, 0xaa, 0x90, 0x18, 0x17, 0x5b, 0x51, 0x6a, 0x71, 0x69, 0x4e, 0x09, 0x54, 0x15,
    0x94, 0x67, 0x94, 0x03, 0x35, 0x2a, 0x18, 0x62, 0x83, 0x50, 0x0c, 0x17, 0xbf, 0x5b, 0x6a, 0x49,
    0x72, 0x06, 0x58, 0xd0, 0xa9, 0x32, 0x34, 0x33, 0x45, 0x48, 0x49, 0x0f, 0x9b, 0x23, 0xf4, 0x90,
    0x5d, 0x20, 0xa5, 0x8c, 0x57, 0x0d, 0xc4, 0x0d, 0x4a, 0x0c, 0x4e, 0xec, 0x51, 0xac, 0x60, 0x89,
    0x24, 0x36, 0xb0, 0xf7, 0x8c, 0x01, 0x01, 0x00, 0x00, 0xff, 0xff, 0x1d, 0x1a, 0x00, 0x10, 0xed,
    0x00, 0x00, 0x00,
}
```

服务端代码
```go
// 指定默认端口，可以通过启动命令行修改
// 版本为了编译后查看和服务替换时进行检查
const (
    appListen  = &quot;:9527&quot;
    appVersion = &quot;1.0.0&quot;
    appName    = &quot;Pluto&quot;
)

// 服务可以通过指定配置文件来启动，基础的配置目前还是依赖配置文件
// 服务启动可以指定两个参数：
// -listen=host:port 指定监听端口
// -config=/your/config/path 指定配置文件
// -version 并不会启动服务，只是会输出一些基础数据，用于查看版本等。
var GlobalConfPath string
var GlobalListen string
var GlobalVersion bool

func init() {
    flag.StringVar(&amp;GlobalConfPath, &quot;config&quot;, &quot;./config/config.yaml&quot;, &quot;Config.yaml&quot;)
    flag.StringVar(&amp;GlobalListen, &quot;listen&quot;, appListen, &quot;Host:port&quot;)
    flag.BoolVar(&amp;GlobalVersion, &quot;version&quot;, false, &quot;Version&quot;)
    flag.Parse()

    util.InitConfigure(GlobalConfPath)
}

// 退出系统
func exitApplication() {
    log.Println(&quot;Exit success...&quot;)
    os.Exit(0)
}

func main() {
    log.Println(&quot;Starting...&quot;)

    // 如果参数是 -version 则只是数据配置
    if GlobalVersion {
        fmt.Println(appName, &quot;:&quot;, appVersion)
        fmt.Println(&quot;Listen:&quot;, GlobalListen)
        fmt.Println(&quot;Config:&quot;, GlobalConfPath)
        os.Exit(0)
    }

    // 创建一个信号监听，如果向该服务发送一些信号，对应作出处理，
    // 这里主要是退出服务
    notifySignal := make(chan os.Signal)
    signal.Notify(notifySignal, syscall.SIGHUP, syscall.SIGINT, syscall.SIGTERM, syscall.SIGQUIT, syscall.SIGUSR1, syscall.SIGUSR2)
    go func() {
        for signalResult := range notifySignal {
            switch signalResult {
            case syscall.SIGHUP, syscall.SIGINT, syscall.SIGTERM, syscall.SIGQUIT, syscall.SIGUSR1, syscall.SIGUSR2:
                exitApplication()
            }
        }
    }()

    log.Println(&quot;Listening....&quot;)

    listen, err := net.Listen(&quot;tcp&quot;, GlobalListen)
    if err != nil {
        log.Fatalf(&quot;Failed to listen: %v&quot;, err)
    }

    // grpc 注册相应的 rpc 服务
    server := grpc.NewServer()
    pb.RegisterApplyServiceServer(server, &amp;service.ApplyService{})
    reflection.Register(server)

    log.Println(&quot;Starting success...&quot;)
    //  开启服务
    if err := server.Serve(listen); err != nil {
        log.Fatalf(&quot;Failed to serve: %v&quot;, err)
    }
}
```
至此，客户端和服务端的代码都完成了，我们部署了 linkerd 和 consul 服务，所以需要我们注册服务到 consul 上，之后我们就可以通过 **127.0.0.1:4141** 端口来调用了，当然直接调用服务的 **9527** 端口也是没问题的，但是我们是集群服务，避免单点，所以需要把服务注册到 consul 上。注册服务我们可以通过代码也可以通过我们的界面管理，因为我们有统一的 webUI 管理界面，所以我们直接通过 webUI 的界面来注册。注册服务的时候有一个非常重要的字段 ServiceName，就是我们前文两次提到的那个名字，只有通过这个名字，服务端和客户端才能通过 linkerd 的代理服务建立起链接。而这一切 linkerd 和 consul 都为我们做好了，我们只需要将服务注册上去即可。

![服务注册](/assets/images/consul_apply_service.png)


PS: 由于咱们墙大，所以 golang 的很多包无法下载，没有代理的话，可以通过 glide mirror 功能设置镜像，大部分 google 域名下的包在 github 都有镜像，可以顺利下载。这个功能太好用了，再补充一个 glidle.yaml 的配置文件内容吧。

```yaml
import:
- package: github.com/golang/protobuf
  version: ^1.0.0
  subpackages:
  - proto
- package: golang.org/x/net
  subpackages:
  - context
- package: golang.org/x/text
  subpackages:
  - unicode
  - secure
- package: google.golang.org/grpc
  subpackages:
  - reflection
- package: google.golang.org/genproto
  subpackages:
  - rpc/status
  - googleapis
- package: google.golang.org/appengine
  subpackages:
  - cloudsql
- package: github.com/olivere/elastic
  version: ^2.0.60
- package: github.com/jmoiron/sqlx
- package: github.com/bradfitz/gomemcache
  subpackages:
  - memcache
- package: golang.org/x/lint
- package: github.com/jinzhu/configor
- package: github.com/BurntSushi/toml
  version: ^0.3.0
```

下面是 .glidle/mirrors.yaml 配置
```yaml
repos:
- original: https://golang.org/x/crypto
  repo: https://github.com/golang/crypto
- original: https://golang.org/x/lint
  repo: https://github.com/golang/lint
- original: https://golang.org/x/net
  repo: https://github.com/golang/net
- original: https://golang.org/x/sys
  repo: https://github.com/golang/sys
- original: https://golang.org/x/text
  repo: https://github.com/golang/text
- original: https://google.golang.org/appengine
  repo: https://github.com/golang/appengine
- original: https://google.golang.org/genproto
  repo: https://github.com/google/go-genproto
- original: https://google.golang.org/grpc
  repo: https://github.com/grpc/grpc-go
```
EOT;</content><author><name></name></author><summary type="html">为什么是实践应用（1）？因为每一个软件都有很多事儿，稍后我们会拆分章节分到每一期去整理和讲解。</summary></entry><entry><title type="html">MySQL 慢查询优化案例（1）</title><link href="http://rust.love/mysql/explain/slow/2018/03/27/mysql-slow-opt.html" rel="alternate" type="text/html" title="MySQL 慢查询优化案例（1）" /><published>2018-03-27T00:00:00+08:00</published><updated>2018-03-27T00:00:00+08:00</updated><id>http://rust.love/mysql/explain/slow/2018/03/27/mysql-slow-opt</id><content type="html" xml:base="http://rust.love/mysql/explain/slow/2018/03/27/mysql-slow-opt.html">问题描述：

&gt; SQL 慢查询，在我们给 x 度做输出抓取的时候，需要扫描全部的帖子，把帖子数据生成固定的格式（XML 文件）让 x 度来抓取。目前 DBA 那边有一个慢查询，大约每天 5000 次执行，查询语句如下：

```sql
select * from `jz_post` where `id` &gt; '{x}' and (`st` = '5') order by `id` asc limit 500
```

这个语句的目的就是取固定状态下所有的帖子，按照 id 分批取，id 是主键，st 也有索引。该语句从 Explain 上看，是使用到索引了，但是 order by 引起性能问题，我们是循环批量取数据，为了保证数据的完整不被遗漏，所以需要 order by，Explain 如下图所示：

![Explain](/assets/images/sql1.png)

这个查询语句虽然用了索引，但是速度还是会非常慢，因为总体数据量大，id 和 st 都是有索引的，如果只是通过 id 和 st 索引，根本解决不了问题，采取的优化手段就是拆分查询，将获取数据分为两部分：

- select id from jz_post where id &gt; '{x}' and st = 5 order by id asc limit 500;
- select * from jz_post where id in ('上一次查询 ID 的结果')

看下 Explain 结果：

![Explain](/assets/images/sql2.png)

从影响的数据行上来看第一次查询 id 已经不存在性能问题了，一定量的 id 取数据也不会有性能问题，带来的后果就是程序里需要单独去再次查询结果集，但是不会影响整个数据库。

EOF;</content><author><name></name></author><summary type="html">问题描述：</summary></entry><entry><title type="html">通过项目来学习 Golang 之 cron.v2 源码分析（一周学习报-第 6 期）</title><link href="http://rust.love/cron.v2/golang/chan/timer/2018/03/23/go-cron-v2.html" rel="alternate" type="text/html" title="通过项目来学习 Golang 之 cron.v2 源码分析（一周学习报-第 6 期）" /><published>2018-03-23T00:00:00+08:00</published><updated>2018-03-23T00:00:00+08:00</updated><id>http://rust.love/cron.v2/golang/chan/timer/2018/03/23/go-cron-v2</id><content type="html" xml:base="http://rust.love/cron.v2/golang/chan/timer/2018/03/23/go-cron-v2.html">根据[第五期](http://rust.love/golang/gin-gonic/crontab/2018/03/09/golang-crontab-web.html)的 cron 项目，理解 cron.v2 项目的源码，主要涉及的知识点

- go 关键字
- chan select
- 闭包
- 接口

先看下源码的结构

```shell
├── LICENSE
├── README.md
├── constantdelay.go 处理特殊时间格式 struct
├── cron.go 负责整个流程控制和调度的 struct
├── doc.go 文档文件
├── parser.go 将输入的 crontab 格式进行转换
└── spec.go Schedule 数据定义和转换
```

整个代码的执行流程
```shell
        NewCron()
          ⇊
Add(Schedule, Command)
          ⇊
    Parse(Schedule)
          ⇊
         Run()
```

主要的相关的源码 ***cron.go***
```go
type Cron struct {
    entries  []*Entry // 一个任务，就是一个 entry
    stop     chan struct{} // 停止任务
    add      chan *Entry // 添加任务
    remove   chan EntryID // 移除任务，每个 Entry 都有一个 ID，稍后介绍
    snapshot chan []Entry // 当前任务
    running  bool // 整个 Cron 是否处于运行状态
    nextID   EntryID // 下一个 Entry
}

// 一个具体的任务
type Entry struct {
    // ID is the cron-assigned ID of this entry, which may be used to look up a
    // snapshot or remove it.
    ID EntryID

    // Schedule on which this job should be run.
    Schedule Schedule

    // Next time the job will run, or the zero time if Cron has not been
    // started or this entry's schedule is unsatisfiable
    Next time.Time

    // Prev is the last time this job was run, or the zero time if never.
    Prev time.Time

    // Job is the thing to run when the Schedule is activated.
    Job Job
}
```

上面的 Entry 里面有两个 struct，我们先来看一下 ***Schedule***，Schedule 是一个 interface，主要是描述了一个 Job 具体运行的时间
```go
// 一个接口
// Schedule describes a job's duty cycle.
type Schedule interface {
    // Next returns the next activation time, later than the given time.
    // Next is invoked initially, and then each time the job is run.
    Next(time.Time) time.Time
}
```

Golang 的接口和其它面向对象语言有所不同，接口和具体实现类不是一个强关联，如上面 Schedule 定义了一个方法 Next，那么任何一个实现了该方法的 struct 都相当于实现了这个接口，如代码中 SpecSchedule 这个 struct，我们可以说他实现了 Schedule 那个接口。如果是一个空接口，没有任何方法，那么所有的 struct 都实现了这个空接口。

```go
// SpecSchedule specifies a duty cycle (to the second granularity), based on a
// traditional crontab specification. It is computed initially and stored as bit sets.
type SpecSchedule struct {
    Second, Minute, Hour, Dom, Month, Dow uint64
    Location                              *time.Location
}

// Next returns the next time this schedule is activated, greater than the given
// time.  If no time can be found to satisfy the schedule, return the zero time.
func (s *SpecSchedule) Next(t time.Time) time.Time {
    // 此处代码省略
}
```

我们真正加入到 Entry 的 Schedule 都是 SpecSchedule，SpecSchedule 的 Next 方法主要是处理下一次 Job 运行时间的方法，该方法里还使用了 goto 关键字，在 Parse 阶段调用的 Parse() 方法将 crontab 格式的数据转换为 SpecSchedule 的实例。

```go
WRAP:
    if t.Year() &gt; yearLimit {
        return time.Time{}
    }

    // Find the first applicable month.
    // If it's this month, then do nothing.
    for 1&lt;&lt;uint(t.Month())&amp;s.Month == 0 {
        // If we have to add a month, reset the other parts to 0.
        if !added {
            added = true
            // Otherwise, set the date at the beginning (since the current time is irrelevant).
            t = time.Date(t.Year(), t.Month(), 1, 0, 0, 0, 0, s.Location)
        }
        t = t.AddDate(0, 1, 0)

        // Wrapped around.
        if t.Month() == time.January {
            goto WRAP
        }
    }
```

goto 关键字是 Golang 控制流程的关键字之一，用起来比较简单，就是在函数某个位置写个标签，后续流程里 goto 到这个标签，跟 C 语言里的 goto 类似。

接下来我们来说一说闭包，闭包这个概念大家多少都有些理解了，结合 cron.v2 的代码，我们来看一看

```go
// FuncJob is a wrapper that turns a func() into a cron.Job
type FuncJob func() // FuncJob 是一个函数类型，好比 type EntryId int

func (f FuncJob) Run() { f() } // 给 FuncJob 增加了一个 Run 方法

// AddFunc adds a func to the Cron to be run on the given schedule.
// spec 就是 crontab 类似的时间格式 */1 * * * 1 或者 @every 5s 这类的
// cmd 这里传进来就是函数例如 AddFunc(&quot;@every 1s&quot;, func () { fmt.Println(&quot;Hello Func&quot;) })
func (c *Cron) AddFunc(spec string, cmd func()) (EntryID, error) {
    return c.AddJob(spec, FuncJob(cmd))
}
```

看下这个例子
```go
package main

import &quot;fmt&quot;

type FFF func()

func (f FFF) printFFF() {
    f()
    fmt.Println(&quot;printFFF&quot;)
}
func main() {
    fp := FFF(func() {
        fmt.Println(&quot;YoYoYo&quot;)
    })
    fp.printFFF()
    fmt.Println(&quot;hello&quot;)
}
// 结果
// YoYoYo
// printFFF
// hello
```

接下来我们来看看 Run 部分的 ***go*** 关键字和 ***chan***，这两个关键字可以说是 Golang 语言的精华所在了。***go*** 关键字主要是用来创建一个 ***goroutine***（协程），而 ***goroutine*** 和 ***chan*** 协作使用，来完成不同 ***goroutine*** 之间的通信。先看一个例子：

```go
package main

import &quot;fmt&quot;
import &quot;time&quot;

func main() {
    var amChan chan int
    fmt.Println(&quot;来通个信&quot;)
    amChan = make(chan int, 5)
    for i := 0; i &lt; 5; i++ {
        // 注释1 go func() {
            amChan &lt;- i

        // 注释1 }()
        // 注释2 time.Sleep(100 * time.Millisecond)
    }
    for i := 0; i &lt; 5; i++ {
        result := &lt;-amChan
        fmt.Println(result)
    }
}
```
上面的代码，如果`注释 1 和 2`部分不打开，输出结果 `0 1 2 3 4`，如果只是打开`注释 1`，我们看到的结果会是 `5 5 5 5 5`，如果`注释 1 和 2`两部分都打开，则会输出 `0 1 2 3 4`。

chan 在我理解起来更像是一个队列，输入数据，取出数据，这里面 `注释 1 和 2` 带来不同的输出结果主要是因为 go 这个关键字开启协程导致的，协程是独立的处理单元，你无法知道他们什么时候真正的启动执行，而注释带来的就是代码逻辑顺序依赖变量 `i`，执行整个 for 循环以后，可能 go 的协程才执行，这样必然带来输出结果不一致的问题。下面我们看下 Cron.Run 方法调用的代码：

```go
// Start the cron scheduler in its own go-routine.
func (c *Cron) Start() {
    c.running = true // 设置状态
    go c.run() // 通过协程来执行 run()
}

// run the scheduler.. this is private just due to the need to synchronize
// access to the 'running' state variable.
func (c *Cron) run() {
    // Figure out the next activation times for each entry.
    now := time.Now().Local()
    // 设置下次执行时间
    for _, entry := range c.entries {
        entry.Next = entry.Schedule.Next(now)
    }

    for {
        // Determine the next entry to run.
        // 排序当前任务的执行时间，排序方法见下面代码
        sort.Sort(byTime(c.entries))

        // effective 就是下次任务要执行的时间
        var effective time.Time
        if len(c.entries) == 0 || c.entries[0].Next.IsZero() {
            // 此处是任务为空时处理逻辑
            // If there are no entries yet, just sleep - it still handles new entries
            // and stop requests.
            effective = now.AddDate(10, 0, 0)
        } else {
            effective = c.entries[0].Next
        }
        // Golang 针对 chan 的读写操作，提供了 select 语句，
        // 可以用 select 来检测或者阻塞 chan 操作的，
        // select 会评估 case 语句块，只要有任何一个评估通过，
        // 就会执行对应的语句，如果都无法通过评估，
        // 则会一直阻塞，直到有语句可以评估通过。
        // 如果都无法通过评估且语句有 `default` 块，则执行 `default` 部分
        select {
            case now = &lt;-time.After(effective.Sub(now)):
                // Run every entry whose next time was this effective time.
                for _, e := range c.entries {
                    if e.Next != effective {
                        break
                    }
                    go e.Job.Run()
                    e.Prev = e.Next
                    e.Next = e.Schedule.Next(effective)
                }
                continue

            case newEntry := &lt;-c.add:
                c.entries = append(c.entries, newEntry)
                newEntry.Next = newEntry.Schedule.Next(now)

            case &lt;-c.snapshot:
                c.snapshot &lt;- c.entrySnapshot()

            case id := &lt;-c.remove:
                c.removeEntry(id)

            case &lt;-c.stop:
                return
        }

        now = time.Now().Local()
    }
}
```

整个 Cron 运行的时候，就是个无限循环，不停的循环 `Cron.entries`，每次循环一个 Entry 任务出来，并计算该任务下次的执行时间，在循环 `entries` 前对其排序，将最近要执行的任务取出来进行和当前时间对比，反复如此，下面就是排序相关代码 `sort.Sort(byTime(c.entries))`

```go
type byTime []*Entry

func (s byTime) Len() int      { return len(s) }
func (s byTime) Swap(i, j int) { s[i], s[j] = s[j], s[i] }
func (s byTime) Less(i, j int) bool {
    // Two zero times should return false.
    // Otherwise, zero is &quot;greater&quot; than any other time.
    // (To sort it at the end of the list.)
    if s[i].Next.IsZero() {
        return false
    }
    if s[j].Next.IsZero() {
        return true
    }
    return s[i].Next.Before(s[j].Next)
}
```

EOF;</content><author><name></name></author><summary type="html">根据第五期的 cron 项目，理解 cron.v2 项目的源码，主要涉及的知识点</summary></entry><entry><title type="html">我的 Spacemaces 坏了</title><link href="http://rust.love/emacs/nss/2018/03/15/emacs-broken.html" rel="alternate" type="text/html" title="我的 Spacemaces 坏了" /><published>2018-03-15T00:00:00+08:00</published><updated>2018-03-15T00:00:00+08:00</updated><id>http://rust.love/emacs/nss/2018/03/15/emacs-broken</id><content type="html" xml:base="http://rust.love/emacs/nss/2018/03/15/emacs-broken.html">因为更新了 spacemacs package，导致每次启动的时候报错，是因为 git 要拉取最新的包，
而无法链接 Github 导致的，在 git clone 时报了一个 SSL connect error 的错误，搞了
半天关于链接 Github 的问题，升级了 libcurl，升级了 git，升级了 openssl，各种折腾不奏效。
最后开启 verbose 信息
```
export GIT_CURL_VERBOSE=1
```

发现 `* NSS error -12190 ` 错误，升级 nss 搞定。

```
sudo yum upgrade nss
```

EOT;</content><author><name></name></author><summary type="html">因为更新了 spacemacs package，导致每次启动的时候报错，是因为 git 要拉取最新的包， 而无法链接 Github 导致的，在 git clone 时报了一个 SSL connect error 的错误，搞了 半天关于链接 Github 的问题，升级了 libcurl，升级了 git，升级了 openssl，各种折腾不奏效。 最后开启 verbose 信息 export GIT_CURL_VERBOSE=1</summary></entry><entry><title type="html">基于 Golang 的 cron 计划任务管理系统（一周学习报-第5期）</title><link href="http://rust.love/golang/gin-gonic/crontab/2018/03/09/golang-crontab-web.html" rel="alternate" type="text/html" title="基于 Golang 的 cron 计划任务管理系统（一周学习报-第5期）" /><published>2018-03-09T00:00:00+08:00</published><updated>2018-03-09T00:00:00+08:00</updated><id>http://rust.love/golang/gin-gonic/crontab/2018/03/09/golang-crontab-web</id><content type="html" xml:base="http://rust.love/golang/gin-gonic/crontab/2018/03/09/golang-crontab-web.html">### 目标
- Golang 环境和基础语法学习
- 学习使用 Golang 构建基本的 web 应用和常用的工具包的使用
- 构建 web 应用中编译、部署等若干注意事项问题

### 项目名称 DCron

DCron 是通过 web 管理计划任务的系统，它并不是直接调用 Linux 的计划任务接口，而是基于 cron.v2 这个 golang 的库构建的，通过 DB 链接了 web 和 cron 计划任务服务。

### 项目目录

```
dcron
├── README.md
├── app
│   ├── bootstrap.go
│   ├── controller
│   └── service
├── application.go // main 入口
├── conf
│   └── conf.yaml
├── logs
│   └── dcron.cli.log
├── resource
│   ├── assets
│   ├── dcron_2018-03-09.sql
│   ├── images
│   └── templates
└── vendor // 依赖
    ├── github.com
    ├── golang.org
    ├── google.golang.org
    ├── gopkg.in
    └── vendor.json
```

### 功能

- 计划任务列表
- 停止删除计划任务
- 查看任务以及任务运行的结果
- 创建计划任务，任务创建时可以制定机器，保证任务可以运行在不同的机器上

Web 服务，如果不制定端口和 Host 可以用一下命令
```go
./dcron
```

Cron 服务

```go
./dcron -mode=cli
```

相关启动代码和参数参考：
```go
func main() {

    mode := flag.String(&quot;mode&quot;, &quot;server&quot;, &quot;-mode=server|cli&quot;)
    port := flag.String(&quot;port&quot;, &quot;8080&quot;, &quot;-port=8080&quot;)
    host := flag.String(&quot;host&quot;, &quot;&quot;, &quot;-host=&quot;)
    flag.Parse()

    if bytes.EqualFold([]byte(*mode), []byte(&quot;cli&quot;)) {
        fmt.Println(&quot;Starting...cli mode...&quot;)
        app.RunCrond()
    } else {
        fmt.Println(&quot;Starting...server mode...&quot;)
        app.RunServer(*host, *port)
    }
}
```

### 项目依赖
因为项目是通过 govendor 来管理的，可以在 vendor 目录下看到相关的依赖

$ govendor list
```javascript
 v  github.com/gin-contrib/sse
 v  github.com/gin-gonic/gin
 v  github.com/gin-gonic/gin/binding
 v  github.com/gin-gonic/gin/json
 v  github.com/gin-gonic/gin/render
 v  github.com/go-sql-driver/mysql
 v  github.com/golang/protobuf/proto
 v  github.com/json-iterator/go
 v  github.com/mattn/go-isatty
 v  github.com/modern-go/concurrent
 v  github.com/modern-go/reflect2
 v  github.com/ugorji/go/codec
 v  gopkg.in/go-playground/validator.v8
 v  gopkg.in/robfig/cron.v2
 v  gopkg.in/yaml.v2
 e  github.com/jinzhu/gorm
 e  github.com/jinzhu/inflection
pl  github.com/outman/dcron
 l  github.com/outman/dcron/app
 l  github.com/outman/dcron/app/controller
 l  github.com/outman/dcron/app/service
  m golang.org/x/sys/unix
  m google.golang.org/appengine/cloudsql
```

### 代码

```
https://github.com/outman/dcron
```

以上是本次主题的一些大纲。</content><author><name></name></author><summary type="html">目标 Golang 环境和基础语法学习 学习使用 Golang 构建基本的 web 应用和常用的工具包的使用 构建 web 应用中编译、部署等若干注意事项问题</summary></entry><entry><title type="html">架构解析 redis cluster 部署 （一周学习报-第4期）</title><link href="http://rust.love/redis/cluster/twemproxy/2018/03/05/redis-cluster.html" rel="alternate" type="text/html" title="架构解析 redis cluster 部署 （一周学习报-第4期）" /><published>2018-03-05T00:00:00+08:00</published><updated>2018-03-05T00:00:00+08:00</updated><id>http://rust.love/redis/cluster/twemproxy/2018/03/05/redis-cluster</id><content type="html" xml:base="http://rust.love/redis/cluster/twemproxy/2018/03/05/redis-cluster.html">### 背景介绍

主要介绍我们目前 redis 部署的架构，我们采用的 redis 是 2.8 版本，所以下面的讲解都是基于这个版本的讲解。

### twemproxy

twemproxy 是 twitter 开发的项目，实现了 redis 和 Memcached 的协议，可以代理 redis 和 Memcached 的请求。关于 twemproxy 不做更多的介绍，我们使用 twemproxy 是采用的 [fnv1a_64](https://en.wikipedia.org/wiki/Fowler%E2%80%93Noll%E2%80%93Vo_hash_function) hash 算法，twemproxy 支持多种 hash 一致性算法，具体的可以看说明文档，根据自身情况采用合适的算法。

### redis-sentinel

因为我们使用的 Redis 版本是 2.8，所以在主从架构中我们使用了 redis-sentinel 来部署，关于 [redis-sentinel 文档可以看这里](http://redisdoc.com/topic/sentinel.html)，几个特性如下：

- 监控（Monitoring）： Sentinel 会不断地检查你的主服务器和从服务器是否运作正常。
- 提醒（Notification）： 当被监控的某个 Redis 服务器出现问题时， Sentinel 可以通过 API 向管理员或者其他应用程序发送通知。
- 自动故障迁移（Automatic failover）： 当一个主服务器不能正常工作时， Sentinel 会开始一次自动故障迁移操作， 它会将失效主服务器的其中一个从服务器升级为新的主服务器， 并让失效主服务器的其他从服务器改为复制新的主服务器； 当客户端试图连接失效的主服务器时， 集群也会向客户端返回新主服务器的地址， 使得集群可以使用新主服务器代替失效服务器。

### 架构现状

目前的架构我们采用了多代理 + 主从结构，而且在代理 twemproxy 层面并没有做 keep-alived，相当于客户端直接面向了多个代理地址，需要客户端自己去完成代理地址是否可用的处理和判断，而 twemproxy 后端对应的是多个 master-slave 结构，master-slave 通过 redis-sentinel 可以进行自动故障迁移，架构图如下：

![redis cluster 工作原理](/assets/images/redis_cluster.jpeg &quot;redis cluster 工作原理&quot;)

客户端在使用的时候是面向了三个地址：

    S1:26370
    S2:26370
    S3:26370

每个 26371 后面对应了三个 (S1,S2,S3):6370，6370 对应的是一个 master-slave 结构，并且是交叉部署在不同的服务器上，从上面的结构可以看出，如果其中一台服务器挂掉是不会有问题的，但是如果 2 台挂掉就会有问题，因为数据是通过 twemproxy hash 不同的 master-slave 结构上的，而 master-slave 也做了交叉部署，如果 1 台 Server 有问题，2 台是可以正常工作的，如果 2 台挂了，就会导致数据丢失。

#### 优点&amp;缺点

- 通过代理在数据存储上进行了数据实例分片，提高了数据存储的容量
- 通过多点部署，基本实现了高可用
- 没有对 twemproxy 做 keepalived，客户端需要面向多个地址，自行判断 server 时否存活，向 PHP 这类语言带来了很大的开销，每次请求都要去处理验活
- 如果两个服务器不可用，数据会丢失

从目前的整体架构上来看，缺点还是比较多的，除了 master-slave 可以自动迁移以外，客户端处理验活也是个问题。

#### 使用过程中的问题

因为目前采用代理，数据是根据 key 进行了分片存储的，所以不支持批量数据操作和一些 select database 这样的操作，如果代码中配置了这样的初始化参数，可能导致无法建立连接等。

### 展望

- twemproxy 配置 keepalived，客户端只关注一个地址
- 升级 Redis，通过 [redis-cluster](http://www.redis.cn/topics/cluster-tutorial.html) 来做集群

### 总结本期的内容

- twemproxy
- redis-sentinel
- redis-cluster

文中也涉及了一些引用链接，大家可以点进去读读，本次内容比较简单，现在也有一些其它的代理工具例如 [Codis](https://github.com/CodisLabs/codis)，都可以自己去了解下。

EOF;</content><author><name></name></author><summary type="html">背景介绍</summary></entry><entry><title type="html">php -l 语法检查之以小见大 （一周学习报-第3期）</title><link href="http://rust.love/php/kernel/gdb/docker/yacc/lexer/bsion/2018/02/24/php-lint.html" rel="alternate" type="text/html" title="php -l 语法检查之以小见大 （一周学习报-第3期）" /><published>2018-02-24T00:00:00+08:00</published><updated>2018-02-24T00:00:00+08:00</updated><id>http://rust.love/php/kernel/gdb/docker/yacc/lexer/bsion/2018/02/24/php-lint</id><content type="html" xml:base="http://rust.love/php/kernel/gdb/docker/yacc/lexer/bsion/2018/02/24/php-lint.html">### 背景

前两期主要是关于系统设计方面的，第 3 期做一期关于 php 源码方面的内容。
我们日常开发和做一些小修改时，尤其是在服务器上，经常使用 php -l 来检测修改的代码是否会导致语法错误，做一些基础的语法检查，所以探究下 php lint 的工作原理很有必要。

### 目标

- 理解 php -l 工作的原理

### 了解 php lint

```php
➜  ~ php -h
Usage: php [options] [-f] &lt;file&gt; [--] [args...]
   php [options] -r &lt;code&gt; [--] [args...]
   php [options] [-B &lt;begin_code&gt;] -R &lt;code&gt; [-E &lt;end_code&gt;] [--] [args...]
   php [options] [-B &lt;begin_code&gt;] -F &lt;file&gt; [-E &lt;end_code&gt;] [--] [args...]
   php [options] -S &lt;addr&gt;:&lt;port&gt; [-t docroot] [router]
   php [options] -- [args...]
   php [options] -a

  ......
  ......
  -h               This help
  -i               PHP information
  -l               Syntax check only (lint)
  ......
  ......
```

在 php 官方的文档中解释如下：

&gt; Provides a convenient way to perform only a syntax check on the given PHP code. On success, the text No syntax errors detected in &lt;filename&gt; is written to standard output and the shell return code is 0. On failure, the text Errors parsing &lt;filename&gt; in addition to the internal parser error message is written to standard output and the shell return code is set to -1.

&gt; **This option won't find fatal errors (like undefined functions). Use the -f to test for fatal errors too.**

Note：
&gt; This option does not work together with the -r option.

### 相关源码解读（v5.5.38）

关于 php 源码的结构和目录功能不在这里复述了，因为线上依然采用的 5.5.x 版本，所以我们也主要以 5.5.38 版本的代码来解读，相关的目录功能在 php 的扩展开发里有很多解释和说明。

因为 php -l 时通过命令行的方式执行的，所以我们主要关注 CLI 部分（涉及 SAPI 概念请自行搜索）。

sapi/cli/php_cli.c
```c
static int do_cli(int argc, char **argv TSRMLS_DC)
{
    // 部分代码省略

    case 'l': /* syntax check mode */
        if (behavior != PHP_MODE_STANDARD) {
            break;
        }
        behavior=PHP_MODE_LINT; // 注意 behavior，将根据 behavior 来做相应的处理动作
        break;

    // 部分代码省略

    case PHP_MODE_LINT:
        // 注意 php_lint_script 这个函数是 main/php_main.h 定义的。
        exit_status = php_lint_script(&amp;file_handle TSRMLS_CC);
        if (exit_status==SUCCESS) {
            zend_printf(&quot;No syntax errors detected in %s\n&quot;, file_handle.filename);
        } else {
            zend_printf(&quot;Errors parsing %s\n&quot;, file_handle.filename);
        }
        break;
}
```

main/main.c
```c
PHPAPI int php_lint_script(zend_file_handle *file TSRMLS_DC)
{
    zend_op_array *op_array;
    int retval = FAILURE;

    zend_try {
        // 此处对文件进行了“编译”，如果失败就会展示上面代码中的错误信息
        op_array = zend_compile_file(file, ZEND_INCLUDE TSRMLS_CC);
        zend_destroy_file_handle(file TSRMLS_CC);

        if (op_array) {
            destroy_op_array(op_array TSRMLS_CC);
            efree(op_array);
            retval = SUCCESS;
        }
    } zend_end_try();

    return retval;
}
```

下面会涉及两个比较重要的文件以及 [lexer 词法分析生成器](https://en.wikipedia.org/wiki/Lex_(software)) 、 [yacc Yet Another Compiler-Compiler](https://en.wikipedia.org/wiki/Yacc)、[re2c lexer generator](http://re2c.org/)、[bison](https://www.gnu.org/software/bison/)

1. Zend/zend_language_scanner.l 词法分析描述文件
2. Zend/zend_language_parser.y 语法描述文件

CG 和 EG
- CG compiler_globals
- EG executor_globals

CG 和 EG 对应的源码在 Zend/zend_globals.h 文件内

SCNG 操作的就是下面这个 struct，也定义在了 Zend/zend_globals.h 文件内
```
_zend_php_scanner_globals
```

Zend/zend_language_scanner.c
```c
ZEND_API zend_op_array *compile_file(zend_file_handle *file_handle, int type TSRMLS_DC)
{
    zend_lex_state original_lex_state;
    zend_op_array *op_array = (zend_op_array *) emalloc(sizeof(zend_op_array));
    zend_op_array *original_active_op_array = CG(active_op_array);
    zend_op_array *retval=NULL;
    int compiler_result;
    zend_bool compilation_successful=0;
    znode retval_znode;
    zend_bool original_in_compilation = CG(in_compilation);

    retval_znode.op_type = IS_CONST;
    retval_znode.u.constant.type = IS_LONG;
    retval_znode.u.constant.value.lval = 1;
    Z_UNSET_ISREF(retval_znode.u.constant);
    Z_SET_REFCOUNT(retval_znode.u.constant, 1);

    zend_save_lexical_state(&amp;original_lex_state TSRMLS_CC);

    retval = op_array; /* success oriented */

    if (open_file_for_scanning(file_handle TSRMLS_CC)==FAILURE) {
        if (type==ZEND_REQUIRE) {
            zend_message_dispatcher(ZMSG_FAILED_REQUIRE_FOPEN, file_handle-&gt;filename TSRMLS_CC);
            zend_bailout();
        } else {
            zend_message_dispatcher(ZMSG_FAILED_INCLUDE_FOPEN, file_handle-&gt;filename TSRMLS_CC);
        }
        compilation_successful=0;
    } else {
        init_op_array(op_array, ZEND_USER_FUNCTION, INITIAL_OP_ARRAY_SIZE TSRMLS_CC);
        CG(in_compilation) = 1;
        CG(active_op_array) = op_array;
        zend_stack_push(&amp;CG(context_stack), (void *) &amp;CG(context), sizeof(CG(context)));
        zend_init_compiler_context(TSRMLS_C);
        // 注意 zendparse
        compiler_result = zendparse(TSRMLS_C);
        zend_do_return(&amp;retval_znode, 0 TSRMLS_CC);
        CG(in_compilation) = original_in_compilation;
        if (compiler_result != 0) { /* parser error */
            zend_bailout();
        }
        compilation_successful=1;
    }

    if (retval) {
        CG(active_op_array) = original_active_op_array;
        if (compilation_successful) {
            pass_two(op_array TSRMLS_CC);
            zend_release_labels(0 TSRMLS_CC);
        } else {
            efree(op_array);
            retval = NULL;
        }
    }
    zend_restore_lexical_state(&amp;original_lex_state TSRMLS_CC);
    return retval;
}
```

zendparse 实际上是 yyparse，在 make 的时候生成在
Zend/zend_language_parse.c 文件中。
```c
/* Substitute the variable and function names.  */
#define yyparse         zendparse
#define yylex           zendlex
#define yyerror         zenderror
#define yylval          zendlval
#define yychar          zendchar
#define yydebug         zenddebug
#define yynerrs         zendnerrs
```

yyparse 的作用就是对输入文件进行语法分析，如果分析成功没有错误则返回 0，否则返回非 0，在语法分析的这个阶段，来判断是否有错误，所以有些执行过程中的 fatal error 是没办法发现的。具体操作的代码，可以通过 GDB 来查看整体流程。

```c
(gdb) break main
(gdb) break zendparse
(gdb) info b
Num     Type           Disp Enb Address            What
1       breakpoint     keep y   0x00000000005ff6f3 in zendparse
                                                   at /root/github/php-src-php-5.5.38/Zend/zend_language_parser.c:3284
    breakpoint already hit 1 time
2       breakpoint     keep y   0x0000000000607c36 in compile_file at Zend/zend_language_scanner.l:554
```

为了方便大家的调试，基于 ubuntu 的镜像自己做了一个 [docker image](https://hub.docker.com/r/0utman/ubuntu-php55-gdb-debug/)，因为 GDB 需要权限，所以 pull 镜像以后，通过下面的命令增加授权参数进入即可
```c
docker pull 0utman/ubuntu-php55-gdb-debug
docker run --privileged -it &lt;image name&gt;
```

自己建立一个有语法错误的文件 syntax_check.php 进行实验吧。
```c
cd /root/
echo &quot;&lt;?php \$0 = 1; &quot; &gt; syntax_check.php
gdb --args php -l syntax_check.php
```

### 总结

文章内容不长，但是涉及的知识点特别多，希望大家能举一反三。

- php 代码执行过程以及 zend 一些相关知识
- lexer yacc bison re2c 编译相关的知识
- gdb 调试
- docker 运用

如果有必要再把里面的一些知识点分为其它的 topic</content><author><name></name></author><summary type="html">背景</summary></entry><entry><title type="html">架构拆解之什么是 CDC（一周学习报-第2期）</title><link href="http://rust.love/cdc/mysql/arch/2018/02/09/cdc.html" rel="alternate" type="text/html" title="架构拆解之什么是 CDC（一周学习报-第2期）" /><published>2018-02-09T00:00:00+08:00</published><updated>2018-02-09T00:00:00+08:00</updated><id>http://rust.love/cdc/mysql/arch/2018/02/09/cdc</id><content type="html" xml:base="http://rust.love/cdc/mysql/arch/2018/02/09/cdc.html">## 背景

在我们的整个架构体系中，我们大量的使用了 CDC，很多同学开始不太清楚，不知道 CDC 是什么，以为 CDC 是一个具体的软件，其实 CDC 是一个统称，就像 Office 代表的是一组办公软件，而 CDC 也是各种不同名字具有 CDC 功能的软件的统称，所以简单介绍下关于 CDC 的内容。文中 CDC 主要是和数据库、MySQL 相关的内容，并不具有广泛的意义。

## 本期目标

- 了解什么是 CDC
- 各种 CDC
- CDC 的一些使用场景和一些想象
- 如何自己实现一个 CDC 软件

### 什么是 CDC

CDC 全称 Change Data Capture，下面是来自[维基百科](https://en.wikipedia.org/wiki/Change_data_capture)的一段说明：

&gt; In databases, change data capture (CDC) is a set of software design patterns used to determine (and track) the data that has changed so that action can be taken using the changed data. Also, Change data capture (CDC) is an approach to data integration that is based on the identification, capture and delivery of the changes made to enterprise data sources.
&gt; CDC solutions occur most often in data-warehouse environments since capturing and preserving the state of data across time is one of the core functions of a data warehouse, but CDC can be utilized in any database or data repository system.

简单来说 CDC 就是记录数据变化的一个工具软件，它可以捕捉每一次的数据变化，我们使用的是阿里开源的 [canal](https://github.com/alibaba/canal)，看下下面的这个图（来自 canal 介绍），基本就理解 CDC 的工作原理了，更详细的可以点开 [canal](https://github.com/alibaba/canal) 链接，有更多的介绍。
![canal 工作原理](/assets/images/canal.jpeg &quot;canal 工作原理&quot;)

### 各种 CDC

因为 CDC 软件繁多，我没有一一安装去实验，所以列举几个，供大家参考，更多的大家可以看[这里](https://github.com/wushujames/mysql-cdc-projects/wiki)。

|名称&amp;站点|描述|
|[canal](https://github.com/alibaba/canal)|阿里巴巴出品，很多中文文档，比较成熟 github star &gt; 4k fork &gt; 1700 多，Java 语言开发，有配套工具链。|
|[databus](https://github.com/linkedin/databus)|star&gt;1800,fork&gt;400, 大厂出品，还是值得信赖的，Java 语言实现|
|[lapidus](https://github.com/JarvusInnovations/lapidus)|Nodejs 实现的 star 76 fork 10|
|[mypipe](https://github.com/mardambey/mypipe)|star&gt;300 fork&gt;50 Scala 实现的|
|[go-mysql-elasticsearch](https://github.com/siddontang/go-mysql-elasticsearch)|star &gt; 1k fork &gt; 250 Golang|
|[php-mysql-replication](https://github.com/krowinski/php-mysql-replication)| PHP 的，哈哈哈|
|[python-mysql-replication](https://github.com/noplay/python-mysql-replication)|Python 的|

### CDC 使用场景和 CDC 在我们架构中的应用

CDC 的应用场景就像它的名字一样，捕捉那些变化的数据，下面简单说几个具体的例子：
- 根据我们的业务，用户报名后会有一些列的数据变化，录取、待面试、拒绝等。
- 电商中的订单状态变
- 数据库数据变更更新检索
- ......

上面列觉的这几个例子，都会涉及到数据变更时，触发一些列的业务操作，直接通过应用程序代码进行异步的事件分发也是可以实现的，代码也可以做到不嵌入业务，但是多业务在共享数据的时候，也会存在一些问题，每个业务方都要去实现监听数据变化的代码。而采用 CDC 进行数据分发，是比较好的实现方式，通过 CDC 统一分发，业务方只关心业务逻辑，不用去写大量代码来做异步实现数据监听接收，下面是我理解的一个基于 CDC 和 Queue 来做的数据分发和共享平台的架构。

![CDC Queue Dispatcher Data](/assets/images/cdc_queue_share_data.jpeg)

通过上面的这套体系，MySQL 通过 CDC 把表变化的数据分发出来，存入相应的共享队列，每个想要使用该数据的的业务方，都可以通过去订阅这份数据来完成自己的业务功能，在代码上基本是完全分离了数据采集的工作。在这里需要注意的是**_数据是单向流向业务方的，所以在数据使用上一定要切合实际的业务功能_**。

目前我们的架构中，只是部分使用了这样的功能，且比较零散，没有从全局上面统筹数据分发，我们应用最多的是数据库数据变化时，更新检索。

### 如何实现一个 CDC？

MySQL 的一些 CDC 软件就是实现了 [MySQL-replication](https://dev.mysql.com/doc/internals/en/replication-protocol.html) 协议的 Slave 库，只是本身并不存储数据，做一些数据解析和分发功能。文中列举了各种语言的实现，并且都有链接地址，大家可以自行部署去玩了。

PS: 本来要自己实现一下发现有 PHP 版本了，😂，大家可以自己查看上面列出来的 PHP 的实现，一个简单的[示例代码](https://github.com/outman/weekly/tree/master/02)。</content><author><name></name></author><summary type="html">背景</summary></entry><entry><title type="html">基于 Redis 的延时队列设计与实现（一周学习报-第1期）</title><link href="http://rust.love/2018/02/04/study_weekly_01.html" rel="alternate" type="text/html" title="基于 Redis 的延时队列设计与实现（一周学习报-第1期）" /><published>2018-02-04T22:46:45+08:00</published><updated>2018-02-04T22:46:45+08:00</updated><id>http://rust.love/2018/02/04/study_weekly_01</id><content type="html" xml:base="http://rust.love/2018/02/04/study_weekly_01.html">### 本期目标
- 了解延时队列的工作原理
- 自己可以通过现有的工具软件来实现延时队列服务


### 延时队列应用场景

延时队列有很多应用场景，简单来说需要在未来某个特定时间去执行的任务，都可以采用延时队列。例如：

- 下订单后 30 分钟未支付的释放订单。
- 用户完成某个功能后，N 天推送个消息。
- 当前我们的使用场景就属于用户被商家处理后，需要 2 天后给用户反馈消息。
- ......

上面提到的这些场景如果不用延时队列都是可以处理的，例如轮训 DB 等，如果采用了延时队列会有更好的效果，除了以上的应用场景，还有很多，可以自己探索。

### 为什么要基于 Redis 去设计一个延时队列

已经很有一些不错的延时队列产品。例如 BeansTalk，但是我们这里只为教学目的，所以自己设计一套，基于 PHP 和 Redis 的代码简单，通过自己设计这个过程，可以增强一些概念和了解原理。

### 使用 RabbitMQ 死信方式存在的问题
- 同一个队列内，数据延时时间不固定，会有阻塞问题。

### 涉及的名词解释

- Queue 就是正常的队列
- enqueue 入队
- dequeue 出对
- Buckt 延时队列数据的存储器
- Scanner 扫描 Bucket，寻找符合条件的数据

### Buckt 设计思路

- 为每条消息生成唯一标识，ZSET 存储数据的延时排序 { value: uuid, score: delay_seconds}
- Hash 存储具体对应的数据 { key : uuid, value : data}

扫描 Bucket 的 ZSET 内的数据，如果 delay_seconds 满足条件，根据 uuid 取出  Hash 内数据，发送到正常队列，删除 ZSET 和 Hash 内的元素。

为了提高效率，降低延时，对整个服务默认分了 4 个 Bucket，每个 Bucket 对应一个进程去扫描处理。文档如下图：

![数据流程和文档 01](/assets/images/study_weekly_01_01.jpeg)
![数据流程和文档 02](/assets/images/study_weekly_01_02.jpeg)

源码地址： [http://github.com/outman](https://github.com/outman/dq)</content><author><name></name></author><summary type="html">本期目标 了解延时队列的工作原理 自己可以通过现有的工具软件来实现延时队列服务</summary></entry><entry><title type="html">reqargs lua tcp socket read timed out</title><link href="http://rust.love/2017/10/30/lua_tcp_socket_read_timed_out_reqargs.html" rel="alternate" type="text/html" title="reqargs lua tcp socket read timed out" /><published>2017-10-30T23:57:58+08:00</published><updated>2017-10-30T23:57:58+08:00</updated><id>http://rust.love/2017/10/30/lua_tcp_socket_read_timed_out_reqargs</id><content type="html" xml:base="http://rust.love/2017/10/30/lua_tcp_socket_read_timed_out_reqargs.html">上传文件，因为还有其它 form 参数，所以使用了 reqargs
模块，发现在错误日志里出现了
```lua
2017/10/30 22:29:42 [error] 15189#0: *641 lua tcp socket read timed out
```

导致这个问题原因有很多，可以搜索下 nginx 相关的一些设置，在调整了 nginx
一些相关的 timeout 参数无果后，去翻了一下 reqargs
的代码，原来是在读取上传文件的时候超时了，而 reqargs 是有 timeout
设置的，只是我没有在文档里看到，详细代码如下：

```lua
elseif sub(ct, 1, 19) == &quot;multipart/form-data&quot; then
local tmpdr = options.tmp_dir or defaults.tmp_dir
if tmpdr and sub(tmpdr, -1) ~= sep then
tmpdr = tmpdr .. sep
end
local maxfz = options.max_file_size    or defaults.max_file_size
local maxfs = options.max_file_uploads or defaults.max_file_uploads
local chunk = options.chunk_size       or defaults.chunk_size
local form, e = upload:new(chunk, options.max_line_size or defaults.max_line_size)
if not form then return nil, e end
local h, p, f, o, s
local u = 0
form:set_timeout(options.timeout or defaults.timeout)
```

这个 timeoutm 如果不设置，默认就是 1000，主要是在模块初始化的时候设置

```lua
local get, post, files = require &quot;reqargs&quot;({timeout = 3600})
```
改为 3600 后，问题消失。</content><author><name></name></author><summary type="html">上传文件，因为还有其它 form 参数，所以使用了 reqargs 模块，发现在错误日志里出现了 2017/10/30 22:29:42 [error] 15189#0: *641 lua tcp socket read timed out</summary></entry></feed>